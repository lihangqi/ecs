# 块存储性能 {#concept_ytm_vwj_ydb .concept}

本文描述了块存储性能的重要指标、不同块存储类型的性能、性能测试方式和结果解读。

## 衡量指标 {#section_b5z_vzv_ydb .section}

衡量块存储产品的性能指标主要包括：IOPS、吞吐量和访问时延。

-   **IOPS**

    IOPS是Input/Output Operations per Second，即每秒能处理的I/O个数，用于表示块存储处理读写（输出/输入）的能力。如果要部署事务密集型应用，典型场景比如数据库类业务应用，需要关注IOPS性能。

    最普遍的IOPS性能指标是顺序操作和随机操作，如下表所示。

    |IOPS性能指标|描述|
    |:-------|:-|
    |总 IOPS|每秒执行的I/O操作总次数。|
    |随机读IOPS|每秒执行的随机读I/O操作的平均次数|对硬盘存储位置的不连续访问。|
    |随机写IOPS|每秒执行的随机写I/O操作的平均次数|
    |顺序读IOPS|每秒执行的顺序读I/O操作的平均次数|对硬盘存储位置的连续访问。|
    |顺序写IOPS|每秒执行的顺序写I/O操作的平均次数|

-   **吞吐量**

    吞吐量是指单位时间内可以成功传输的数据数量。

    如果要部署大量顺序读写的应用，典型场景比如Hadoop离线计算型业务，需要关注吞吐量。

-   **访问时延**

    访问时延是指块存储处理一个I/O需要的时间。

    如果您的应用对时延比较敏感，比如数据库（过高的时延会导致应用性能下降或报错），建议您使用SSD云盘、SSD共享块存储或本地SSD盘类产品。

    如果您的应用更偏重存储吞吐能力，对时延相对不太敏感，比如Hadoop离线计算等吞吐密集型应用，建议您使用本地HDD盘类产品，如d1或d1ne大数据型实例。


## 性能 {#section_i5z_vzv_ydb .section}

以下是不同块存储产品的性能对比表。

块存储按照二进制单位计算，单位为GiB、KiB、TiB或者MiB。

**说明：** 二进制单位用于表示*1024进位*的数据大小。例如，1 GiB = 1024 MiB。

-   **云盘性能**

    四种云盘的性能对比如下表所示。

    |参数|ESSD云盘|SSD云盘|高效云盘|普通云盘|
    |:-|:-----|:----|:---|:---|
    |单盘最大容量|32768 GiB|32768 GiB|32768 GiB|2000 GiB|
    |最大IOPS|1000000|25000\*|5000|数百|
    |最大吞吐量|4000 MBps|300 MBps\*|140 MBps|30−40 MBps|
    |单盘性能计算公式\*\*|IOPS = min\{1800 + 50 \* 容量, 1000000\}|IOPS = min\{1800 + 30 \* 容量, 25000\}|IOPS = min\{1800 + 8 \* 容量, 5000\}|无|
    |吞吐量 = min\{120 + 0.5 \* 容量, 4000\} MBps|吞吐量 = min\{120 + 0.5 \* 容量, 300\} MBps|吞吐量 = min\{100+ 0.15 \* 容量, 140\} MBps|无|
    |数据可靠性|99.9999999%|99.9999999%|99.9999999%|99.9999999%|
    |API名称|cloud\_essd|cloud\_ssd|cloud\_efficiency|cloud|
    |典型应用场景|     -   OLTP数据库：如MySQL、PostgreSQL、Oracle、SQL Server等关系型数据库
    -   NoSQL数据库：如MongoDB、HBase、Cassandra等非关系型数据库
    -   ElasticSearch分布式日志：ELK（Elasticsearch、Logstash和Kibana）日志分析等
 |     -   PostgreSQL、MySQL、Oracle、SQL Server等中大型关系数据库应用
    -   对数据可靠性要求高的中大型开发测试环境
 |     -   MySQL、SQL Server、PostgreSQL等中小型关系数据库应用
    -   对数据可靠性要求高、中度性能要求的中大型开发测试应用
 |     -   数据不被经常访问或者低I/O负载的应用场景（如果应用需要更高的I/O性能，建议使用SSD云盘）
    -   需要低成本并且有随机读写I/O的应用环境
 |

    \* SSD云盘的性能因数据块大小而异，数据块越小，吞吐量越小，IOPS越高，如下表所示。只有挂载到I/O优化的实例时，SSD云盘才能获得期望的IOPS性能。挂载到非I/O优化的实例时，SSD云盘无法获得期望的IOPS性能。

    |数据块大小|IOPS最大值|吞吐量|
    |:----|:------|:--|
    |4 KiB|约25000|很小，远低于300 MBps|
    |16 KiB|约17200|将近300 MBps|
    |32 KiB|约9600|
    |64 KiB|约4800|

    \*\* 单盘性能计算公式说明：

    -   以单块SSD云盘最大IOPS计算公式为例说明：起步1800 IOPS，每GiB增加30 IOPS，最高25000 IOPS。
    -   以单块SSD云盘最大吞吐量计算公式为例说明：起步120 MBps，每GiB增加0.5 MBps，上限为 300 MBps的吞吐量。
    不同云盘的单路随机写访问时延如下：

    -   ESSD云盘：0.1−0.2 ms
    -   SSD云盘：0.5−2 ms
    -   高效云盘：1−3 ms
    -   普通云盘：5−10 ms
-   **共享块存储性能**

    2种共享块存储的性能对比如下表所示。

    |参数|SSD共享块存储|高效共享块存储|
    |:-|:-------|:------|
    |最大容量|     -   单盘：32768 GiB
    -   单个实例：最大128 TiB
 |     -   单盘：32768 GiB
    -   单个实例：最大128 TiB
 |
    |最大随机读写IOPS\*|30000|5000|
    |最大顺序读写吞吐量\*|512 MBps|160 MBps|
    |单盘性能计算公式\*\*|IOPS = min\{1600 + 40 \* 容量, 30000\}|IOPS = min\{1000 + 6 \* 容量, 5000\}|
    |吞吐量 = min\{100 + 0.5 \* 容量, 512\} MBps|吞吐量 = min\{50 + 0.15 \* 容量, 160\} MBps|
    |典型应用场景|     -   Oracle RAC
    -   SQL Server
    -   故障转移集群
    -   服务器高可用
 |     -   服务器高可用架构
    -   开发测试数据库高可用架构
 |

    \* 最大IOPS和吞吐量是在2个或2个以上实例同时压测裸设备能达到的性能数值。

    \*\* 单盘性能计算公式说明：

    -   以单块SSD共享块存储最大IOPS计算公式为例：起步1600 IOPS，每GiB增加40 IOPS，最高30000 IOPS。
    -   以单块SSD共享块存储最大吞吐量计算公式为例：起步100 MBps，每GiB增加0.5 MBps，上限为512 MBps的吞吐量。
    不同共享块存储的单路访问时延如下：

    -   SSD共享块存储：0.5−2 ms
    -   高效共享块存储：1−3 ms
-   **本地盘性能**

    本地盘的性能信息，请参考 [本地盘](intl.zh-CN/产品简介/块存储/本地盘.md#)。


## 性能测试 {#section_jvz_vzv_ydb .section}

Linux实例和Windows实例都推荐使用FIO工具进行测试块存储性能。

**说明：** 您也可以使用其他工具测试块存储性能，但不同工具测试出来的硬盘基准性能会有差异，如dd、sysbench、iometer等工具可能会受到测试参数配置和文件系统影响，难以反映真实的磁盘性能。本文中所描述的性能参数，均为Linux实例下采用FIO工具的测试结果，以此作为块存储产品性能指标参考。

本文以Linux实例和FIO为例，说明如何使用FIO测试块存储性能。在进行测试前，请确保块存储设备已经4 KiB对齐。

**警告：** 测试裸盘可以获得真实的块存储盘性能，但直接测试裸盘会破坏文件系统结构，请在测试前提前做好数据备份。建议您只在新购无数据的ECS实例上使用工具测试块存储性能，避免造成数据丢失。

-   测试随机写IOPS，运行以下命令：

    ```
    fio -direct=1 -iodepth=128 -rw=randwrite -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=iotest -name=Rand_Write_Testing
    ```

-   测试随机读IOPS，运行以下命令：

    ```
    fio -direct=1 -iodepth=128 -rw=randread -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=iotest -name=Rand_Read_Testing
    ```

-   测试顺序写吞吐量，运行以下命令：

    ```
    fio -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=1024k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=iotest -name=Write_PPS_Testing
    ```

-   测试顺序读吞吐量，运行以下命令：

    ```
    fio -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=1024k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=iotest -name=Read_PPS_Testing
    ```


下表以测试随机写IOPS的命令为例，说明命令中各种参数的含义。

|参数|说明|
|:-|:-|
|-direct=1|表示测试时忽略I/O缓存，数据直写。|
|-iodepth=128|表示使用AIO时，同时发出I/O数的上限为128。|
|-rw=randwrite|表示测试时的读写策略为随机写（random writes）。作其它测试时可以设置为：-   randread（随机读random reads）
-   read（顺序读sequential reads）
-   write（顺序写sequential writes）
-   randrw（混合随机读写mixed random reads and writes）

|
|-ioengine=libaio|表示测试方式为libaio（Linux AIO，异步I/O）。应用程序使用I/O通常有两种方式：-   同步

同步的I/O一次只能发出一个I/O请求，等待内核完成才返回。这样对于单个线程iodepth总是小于1，但是可以透过多个线程并发执行来解决。通常会用16−32根线程同时工作将iodepth塞满。

-   异步

异步的I/O通常使用libaio这样的方式一次提交一批I/O请求，然后等待一批的完成，减少交互的次数，会更有效率。


|
|-bs=4k| 表示单次I/O的块文件大小为4 KB。未指定该参数时的默认大小也是4 KB。

 测试IOPS时，建议将`bs`设置为一个比较小的值，如本示例中的4k。

 测试吞吐量时，建议将`bs`设置为一个较大的值，如本示例中的1024k。

 |
|-size=1G|表示测试文件大小为1 GiB。|
|-numjobs=1|表示测试线程数为1。|
|-runtime=1000|表示测试时间为1000秒。如果未配置，则持续将前述`-size`指定大小的文件，以每次`-bs`值为分块大小写完。|
|-group\_reporting|表示测试结果里汇总每个进程的统计信息，而非以不同job汇总展示信息。|
|-filename=iotest|指定测试文件的名称，比如iotest。测试裸盘可以获得真实的硬盘性能，但直接测试裸盘会破坏文件系统结构，请在测试前提前做好数据备份。|
|-name=Rand\_Write\_Testing|表示测试任务名称为Rand\_Write\_Testing，可以随意设定。|

